# Анализ данных и проекты машинного обучения

Этот репозиторий содержит четыре файла (`NIR_3 (1).R`, `4_NIR (2).pdf`, `NIR_5 (1).pdf`, `6_NIR (1).pdf`), которые документируют задачи анализа данных и машинного обучения, выполненные на различных наборах данных. Каждый файл посвящен различным наборам данных и методологиям, включая регрессионное моделирование, классификацию, снижение размерности и кластеризацию. Ниже приведено подробное описание каждого файла, его целей и ключевых выводов.

## Обзор файлов

### 1. NIR_3 (1).R
- **Описание**: Скрипт на языке R, анализирующий данные опроса Российской лонгитюдной мониторинговой системы (RLMS), волна 27, вариант 14 (`r27i_os_31.csv`). Скрипт выполняет линейную регрессию для моделирования среднемесячной зарплаты (`wj13.2`) на основе факторов, таких как пол, семейное положение, образование, возраст, тип населенного пункта и продолжительность рабочей недели.
- **Основные задачи**:
  - **Предобработка данных**: Загрузка и очистка данных, удаление пропущенных значений, нормализация числовых переменных (зарплата, возраст, продолжительность рабочей недели). Категориальные переменные (пол, семейное положение, образование, тип населенного пункта) кодируются как фиктивные переменные.
  - **Построение моделей**: Создание нескольких моделей линейной регрессии, устранение мультиколлинеарности (например, удаление `wed3` из-за линейной зависимости) и тестирование преобразований (логарифмических и степенных для `age`, `dur`, `salary`).
  - **Оценка моделей**: Сравнение моделей по R², p-значениям и коэффициенту инфляции дисперсии (VIF). Лучшая модель (`model3_2`) достигает R² = 0.2421, объясняя зависимость зарплаты от пола, возраста, типа населенного пункта и продолжительности рабочей недели.
  - **Статистический анализ**: Вычисление критических значений t-критерия и доверительных интервалов для оценки значимости отдельных предикторов (например, мужчины зарабатывают больше, высшее образование связано с более высокой зарплатой).
  - **Анализ подгрупп**: Исследование конкретных подгрупп (например, женатые мужчины с высшим образованием, разведенные мужчины в городах) для изучения влияния переменных.
- **Ключевые выводы**:
  - Лучшая модель (`model3_2`) показывает, что пол, возраст (с преобразованием степени 1.2), тип населенного пункта и продолжительность рабочей недели значительно предсказывают зарплату.
  - Анализ подгрупп выявил, что для женатых мужчин с высшим образованием переменные не оказывают значимого влияния на зарплату (R² = -0.2638, p-значение = 0.9608). Для разведенных мужчин в городах значимыми являются высшее образование, возраст и продолжительность рабочей недели (R² = 0.7309).
  - Значимые предикторы: пол (мужчины зарабатывают больше), высшее образование (положительный эффект), продолжительность рабочей недели (более длинные часы коррелируют с более высокой зарплатой).

### 2. 4_NIR (2).pdf
- **Описание**: PDF-отчет, описывающий задачу классификации на наборе данных `StudentsPerformance.csv`, выполненную на Python, для предсказания завершения подготовительного курса к тестированию. Используются классификаторы Decision Tree и Random Forest с применением SMOTE для устранения дисбаланса классов.
- **Основные задачи**:
  - **Предобработка данных**: Переименование столбцов, кодирование целевой переменной (`test_preparation_course`: none=0, completed=1), применение one-hot кодирования к категориальным признакам. SMOTE балансирует данные (исходное распределение классов: 64.2% не завершили, 35.8% завершили).
  - **Обучение моделей**: Использование GridSearchCV для оптимизации классификаторов Decision Tree (`max_depth`, `min_samples_split`, `class_weight`) и Random Forest (`n_estimators`, `max_depth`, `class_weight`) с метрикой F1-score.
  - **Оценка моделей**: Сравнение производительности по точности (precision), полноте (recall) и F1-score. Визуализация первого дерева из Random Forest и графика топ-10 важных признаков.
- **Ключевые выводы**:
  - Decision Tree: Precision = 0.66, Recall = 0.67, F1 = 0.67 (лучше обнаруживает студентов, завершивших подготовку).
  - Random Forest: Precision = 0.79, Recall = 0.58, F1 = 0.67 (более точен, но пропускает некоторые положительные случаи).
  - Основные признаки: уровень образования родителей, баллы за письмо и тип питания, что указывает на их важность для предсказания завершения курса.

### 3. NIR_5 (1).pdf
- **Описание**: PDF-отчет, анализирующий набор данных `diamonds.csv` с использованием Python для исследовательского анализа данных, предобработки и снижения размерности. Цель — изучить характеристики алмазов и их связь с ценой.
- **Основные задачи**:
  - **Исследовательский анализ**: Определение размера набора данных (53,940 строк, 10 столбцов), категориальных признаков (`cut`, `color`, `clarity`) и числовых признаков (`carat`, `depth`, `table`, `price`, `x`, `y`, `z`). Пропуски отсутствуют, бинарных признаков нет.
  - **Удаление выбросов**: Использование метода межквартильного размаха (IQR) для удаления 7,400 строк с выбросами в числовых признаках.
  - **Нормализация данных**: Применение `StandardScaler` к числовым признакам, достижение средних значений, близких к нулю.
  - **Корреляционный анализ**: Визуализация корреляций, показывающая сильную связь между `carat` и `price` (0.92), а также между `carat` и размерами (`x`, `y`, `z`: 0.96–0.99).
  - **PCA и t-SNE**: Проведение PCA для сохранения 90% дисперсии (требуется 11 компонент) и t-SNE для визуализации, выявление двух кластеров (дорогие/крупные vs. дешевые/мелкие алмазы).
- **Ключевые выводы**:
  - Признак `carat` имеет наибольший вклад в первую компоненту PCA и сильно коррелирует с ценой и размерами.
  - Визуализация t-SNE показывает два четких кластера, основанных на цене и размере, подтверждая структурные различия в данных.

### 4. 6_NIR (1).pdf
- **Описание**: PDF-отчет, расширяющий анализ набора данных `diamonds.csv` с использованием кластеризации, обнаружения аномалий и предсказательного моделирования на Python.
- **Основные задачи**:
  - **Исследовательский анализ**: Подтверждение 53,940 записей без пропусков. Визуализация распределений числовых признаков и корреляций, подчеркивающая сильную связь `carat`-`price` (0.92) и `carat`-размеры (0.95–0.98).
  - **Кластеризация**: Использование KMeans с оценкой силуэта для определения оптимального числа кластеров (2). Визуализация t-SNE подтверждает два кластера (премиальные vs. стандартные алмазы).
  - **Обнаружение аномалий**: Применение IQR (3,540 аномалий), Isolation Forest (2,697 аномалий) и DBSCAN (104 аномалии). Выявлено 24 общих аномалии между всеми методами.
  - **Предсказательное моделирование**: Обучение моделей Linear Regression, Random Forest и XGBoost для предсказания `price`. Оценка по R², MAE и RMSE. Важность признаков Random Forest подчеркивает доминирование `carat` (64.8%) и `x` (26.5%).
- **Ключевые выводы**:
  - XGBoost показывает лучшую производительность (R² = 0.979, MAE = 297.7, RMSE = 579.6), что делает его подходящим для предсказания цены.
  - Кластеризация и t-SNE подтверждают наличие двух различных групп в данных.
  - Обнаружение аномалий выявляет выбросы, с 24 точками, стабильно отмеченными всеми методами, вероятно, представляющими необычные комбинации цены или размера.

## Ключевые выводы
- **Анализ зарплат (NIR_3)**: Зарплата значительно зависит от пола, высшего образования и продолжительности рабочей недели, причем возраст оказывает нелинейное влияние (преобразование степени 1.2 улучшает модель).
- **Успеваемость студентов (4_NIR)**: Decision Tree и Random Forest достигают одинакового F1-score (0.67), при этом Random Forest более точен, а Decision Tree имеет лучшую полноту. Уровень образования родителей и баллы за письмо — ключевые предикторы.
- **Анализ алмазов (NIR_5, 6_NIR)**: `carat` — основной фактор цены алмазов, с сильной корреляцией с размерами. Выявлено два кластера (премиальные vs. стандартные алмазы), а XGBoost обеспечивает лучшие предсказания цены.
